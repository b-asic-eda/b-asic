"""Module for generating cocotb test benches."""

from collections import defaultdict
from pathlib import Path
from pprint import pformat

from apytypes import APyCFixed, APyCFloat

from b_asic.architecture import Architecture
from b_asic.simulation import ResultArrayMap
from b_asic.special_operations import Input, Output


class CocotbPrinter:
    """
    Class for generating cocotb test benches.

    Parameters
    ----------
    sim_results : ResultArrayMap
        Simulation results mapping graph IDs to their output values over iterations.
    """

    _sim_results: ResultArrayMap

    def __init__(self, sim_results: ResultArrayMap):
        self._sim_results = sim_results

    def print(
        self,
        arch: Architecture,
        *,
        path: str | Path = Path(),
        simulator: str = "ghdl",
        waves: bool = False,
        gui: bool = False,
        csv: bool = False,
    ) -> None:
        """
        Generate the cocotb test bench files.

        Parameters
        ----------
        arch : Architecture
            The architecture to generate the testbench for.
        path : str or Path, default Path()
            The output directory path, defaults to the current directory.
        simulator : str, default "ghdl"
            The simulator to use (e.g., "ghdl", "nvc").
        waves : bool, default False
            Whether to dump waveforms when running the testbench.
        gui : bool, default False
            Whether to launch the simulator GUI when running the testbench.
            If the simulator lacks a GUI, a waveform viewer will be launched, if possible.
        csv : bool, default False
            Whether to dump input and output values to a CSV file during simulation.
        """
        path = Path(path)

        template_path = Path(__file__).parent / "template.py"
        with Path.open(template_path) as template_file:
            template = template_file.read()

        is_complex = any(
            isinstance(v[0], (complex, APyCFixed, APyCFloat))
            for v in self._sim_results.values()
        )

        # Track which graph_ids have been marked as input/output and their schedule
        io_marked = {}

        # First, scan architecture to mark which gids are inputs vs outputs
        for pe in arch.processing_elements:
            if pe.operation_type not in (Input, Output):
                continue
            for pe_process in pe.collection:
                gid = pe_process.operation.graph_id
                io_marked[gid] = {
                    "is_input": pe.operation_type is Input,
                    "pe_name": pe.entity_name,
                    "start_time": pe_process.start_time,
                }

        seq_map = defaultdict(dict)

        # Track which (gid, sample_idx) pairs have been processed
        processed = set()

        # Now populate sequence map
        for gid in io_marked:
            values = self._sim_results[gid]

            for sample_idx in range(len(values)):
                value = values[sample_idx]
                pe_name = io_marked[gid]["pe_name"]
                is_input = io_marked[gid]["is_input"]
                start_time = io_marked[gid]["start_time"]
                schedule_time = arch.schedule_time

                # Calculate actual hardware cycle time
                time = start_time + sample_idx * schedule_time

                if is_complex:
                    if is_input:
                        seq_map[time][f"{pe_name}_0_in_re"] = value.to_bits()[0]
                        seq_map[time][f"{pe_name}_0_in_im"] = value.to_bits()[1]
                    else:
                        seq_map[time][f"{pe_name}_0_out_re"] = value.to_bits()[0]
                        seq_map[time][f"{pe_name}_0_out_im"] = value.to_bits()[1]
                else:
                    if is_input:
                        seq_map[time][f"{pe_name}_0_in"] = value.to_bits()
                    else:
                        seq_map[time][f"{pe_name}_0_out"] = value.to_bits()

                processed.add((gid, sample_idx))

        seq_map = dict(seq_map)

        compile_order = self._get_compile_order(arch, path)

        # Replace the file docstring
        tb_content = template.replace(
            '"""Template for cocotb testbench."""',
            '"""cocotb testbench generated by B-ASIC."""',
        )

        # Replace placeholders in the template with actual values
        sources_str = "[" + ", ".join(f'Path("{file}")' for file in compile_order) + "]"
        tb_content = tb_content.replace("SOURCES = []", f"SOURCES = {sources_str}")
        tb_content = tb_content.replace(
            'SIMULATOR = ""',
            f'SIMULATOR = "{simulator}"',
        )
        tb_content = tb_content.replace(
            "SEQUENCE = {}",
            f"SEQUENCE = {pformat(seq_map, indent=4)}",
        )
        tb_content = tb_content.replace(
            'ENTITY_NAME = ""', f'ENTITY_NAME = "{arch.entity_name}"'
        )
        tb_content = tb_content.replace("WAVES = False", f"WAVES = {waves!s}")
        tb_content = tb_content.replace("GUI = False", f"GUI = {gui!s}")
        tb_content = tb_content.replace("CSV = False", f"CSV = {csv!s}")

        with Path.open(path / "tb.py", "w") as output_file:
            output_file.write(tb_content)

        with Path.open(path / "Makefile", "w") as makefile:
            makefile.write("SIM ?= ghdl\n")
            makefile.write("TOPLEVEL_LANG ?= vhdl\n\n")
            makefile.write("PWD := $(shell pwd)\n\n")

            vhdl_sources = " ".join(f'"$(PWD)/{file}"' for file in compile_order)
            makefile.write(f"VHDL_SOURCES := {vhdl_sources}\n\n")

            makefile.write(f"COCOTB_TOPLEVEL ?= {arch.entity_name}\n")
            makefile.write("COCOTB_TEST_MODULES ?= tb\n\n")
            makefile.write("include $(shell cocotb-config --makefiles)/Makefile.sim\n")

    def _get_compile_order(self, arch: Architecture, path: Path) -> list[str]:
        order = []
        if (path / "types.vhdl").exists():
            order.append("types.vhdl")
        for mem in arch.memories:
            filename = f"{mem.entity_name}.vhdl"
            if (path / filename).exists():
                order.append(filename)
        for pe in arch.processing_elements:
            filename = f"{pe.entity_name}.vhdl"
            if (path / filename).exists():
                order.append(filename)
        arch_file = f"{arch.entity_name}.vhdl"
        if (path / arch_file).exists():
            order.append(arch_file)
        return order
